# Optimizing-Deep-Learning-with-Quantization
Explore Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) to reduce memory and computational demand without sacrificing performance. Dive into precision trade-offs, bit-width evaluations, and scaling law analysis, all using PyTorch and CIFAR-100 for edge-ready AI models.
